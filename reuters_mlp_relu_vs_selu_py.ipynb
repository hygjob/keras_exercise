{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuters_mlp_relu_vs_selu.py.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hygjob/keras_exercise/blob/master/reuters_mlp_relu_vs_selu_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjETT3r9frLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2175cc9-cc12-475f-ade2-850f5e48dedc"
      },
      "source": [
        "'''Compares self-normalizing MLPs with regular MLPs.\n",
        "\n",
        "Compares the performance of a simple MLP using two\n",
        "different activation functions: RELU and SELU\n",
        "on the Reuters newswire topic classification task.\n",
        "\n",
        "# Reference\n",
        "\n",
        "- Klambauer, G., Unterthiner, T., Mayr, A., & Hochreiter, S. (2017).\n",
        "  Self-Normalizing Neural Networks. arXiv preprint arXiv:1706.02515.\n",
        "  https://arxiv.org/abs/1706.02515\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import reuters\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_words = 1000\n",
        "batch_size = 16\n",
        "epochs = 40\n",
        "plot = True\n",
        "\n",
        "\n",
        "def create_network(n_dense=6,\n",
        "                   dense_units=16,\n",
        "                   activation='selu',\n",
        "                   dropout=AlphaDropout,\n",
        "                   dropout_rate=0.1,\n",
        "                   kernel_initializer='lecun_normal',\n",
        "                   optimizer='adam',\n",
        "                   num_classes=1,\n",
        "                   max_words=max_words):\n",
        "    \"\"\"Generic function to create a fully-connected neural network.\n",
        "\n",
        "    # Arguments\n",
        "        n_dense: int > 0. Number of dense layers.\n",
        "        dense_units: int > 0. Number of dense units per layer.\n",
        "        dropout: keras.layers.Layer. A dropout layer to apply.\n",
        "        dropout_rate: 0 <= float <= 1. The rate of dropout.\n",
        "        kernel_initializer: str. The initializer for the weights.\n",
        "        optimizer: str/keras.optimizers.Optimizer. The optimizer to use.\n",
        "        num_classes: int > 0. The number of classes to predict.\n",
        "        max_words: int > 0. The maximum number of words per data point.\n",
        "\n",
        "    # Returns\n",
        "        A Keras model instance (compiled).\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Dense(dense_units, input_shape=(max_words,),\n",
        "                    kernel_initializer=kernel_initializer))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(dropout(dropout_rate))\n",
        "\n",
        "    for i in range(n_dense - 1):\n",
        "        model.add(Dense(dense_units, kernel_initializer=kernel_initializer))\n",
        "        model.add(Activation(activation))\n",
        "        model.add(dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "network1 = {\n",
        "    'n_dense': 6,\n",
        "    'dense_units': 16,\n",
        "    'activation': 'relu',\n",
        "    'dropout': Dropout,\n",
        "    'dropout_rate': 0.5,\n",
        "    'kernel_initializer': 'glorot_uniform',\n",
        "    'optimizer': 'sgd'\n",
        "}\n",
        "\n",
        "network2 = {\n",
        "    'n_dense': 6,\n",
        "    'dense_units': 16,\n",
        "    'activation': 'selu',\n",
        "    'dropout': AlphaDropout,\n",
        "    'dropout_rate': 0.1,\n",
        "    'kernel_initializer': 'lecun_normal',\n",
        "    'optimizer': 'sgd'\n",
        "}\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n",
        "                                                         test_split=0.2)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "num_classes = np.max(y_train) + 1\n",
        "print(num_classes, 'classes')\n",
        "\n",
        "print('Vectorizing sequence data...')\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Convert class vector to binary class matrix '\n",
        "      '(for use with categorical_crossentropy)')\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "\n",
        "print('\\nBuilding network 1...')\n",
        "\n",
        "model1 = create_network(num_classes=num_classes, **network1)\n",
        "history_model1 = model1.fit(x_train,\n",
        "                            y_train,\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            verbose=1,\n",
        "                            validation_split=0.1)\n",
        "\n",
        "score_model1 = model1.evaluate(x_test,\n",
        "                               y_test,\n",
        "                               batch_size=batch_size,\n",
        "                               verbose=1)\n",
        "\n",
        "\n",
        "print('\\nBuilding network 2...')\n",
        "model2 = create_network(num_classes=num_classes, **network2)\n",
        "\n",
        "history_model2 = model2.fit(x_train,\n",
        "                            y_train,\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            verbose=1,\n",
        "                            validation_split=0.1)\n",
        "\n",
        "score_model2 = model2.evaluate(x_test,\n",
        "                               y_test,\n",
        "                               batch_size=batch_size,\n",
        "                               verbose=1)\n",
        "\n",
        "print('\\nNetwork 1 results')\n",
        "print('Hyperparameters:', network1)\n",
        "print('Test score:', score_model1[0])\n",
        "print('Test accuracy:', score_model1[1])\n",
        "print('Network 2 results')\n",
        "print('Hyperparameters:', network2)\n",
        "print('Test score:', score_model2[0])\n",
        "print('Test accuracy:', score_model2[1])\n",
        "\n",
        "plt.plot(range(epochs),\n",
        "         history_model1.history['val_loss'],\n",
        "         'g-',\n",
        "         label='Network 1 Val Loss')\n",
        "plt.plot(range(epochs),\n",
        "         history_model2.history['val_loss'],\n",
        "         'r-',\n",
        "         label='Network 2 Val Loss')\n",
        "plt.plot(range(epochs),\n",
        "         history_model1.history['loss'],\n",
        "         'g--',\n",
        "         label='Network 1 Loss')\n",
        "plt.plot(range(epochs),\n",
        "         history_model2.history['loss'],\n",
        "         'r--',\n",
        "         label='Network 2 Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('comparison_of_networks.png')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "8982 train sequences\n",
            "2246 test sequences\n",
            "46 classes\n",
            "Vectorizing sequence data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0830 07:48:18.883533 140610532136832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0830 07:48:18.919053 140610532136832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0830 07:48:18.928068 140610532136832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0830 07:48:18.952102 140610532136832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0830 07:48:18.961683 140610532136832 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (8982, 1000)\n",
            "x_test shape: (2246, 1000)\n",
            "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
            "y_train shape: (8982, 46)\n",
            "y_test shape: (2246, 46)\n",
            "\n",
            "Building network 1...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0830 07:48:19.123633 140610532136832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0830 07:48:19.149090 140610532136832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0830 07:48:19.283622 140610532136832 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8083 samples, validate on 899 samples\n",
            "Epoch 1/40\n",
            "8083/8083 [==============================] - 2s 191us/step - loss: 3.3098 - acc: 0.3321 - val_loss: 2.6318 - val_acc: 0.3315\n",
            "Epoch 2/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.5547 - acc: 0.3525 - val_loss: 2.2595 - val_acc: 0.3315\n",
            "Epoch 3/40\n",
            "8083/8083 [==============================] - 1s 105us/step - loss: 2.3684 - acc: 0.4065 - val_loss: 2.2011 - val_acc: 0.4894\n",
            "Epoch 4/40\n",
            "8083/8083 [==============================] - 1s 109us/step - loss: 2.2684 - acc: 0.4679 - val_loss: 2.1586 - val_acc: 0.4950\n",
            "Epoch 5/40\n",
            "8083/8083 [==============================] - 1s 108us/step - loss: 2.2470 - acc: 0.4749 - val_loss: 2.1289 - val_acc: 0.5050\n",
            "Epoch 6/40\n",
            "8083/8083 [==============================] - 1s 109us/step - loss: 2.2178 - acc: 0.4780 - val_loss: 2.1253 - val_acc: 0.5028\n",
            "Epoch 7/40\n",
            "8083/8083 [==============================] - 1s 110us/step - loss: 2.1731 - acc: 0.4942 - val_loss: 2.1039 - val_acc: 0.5006\n",
            "Epoch 8/40\n",
            "8083/8083 [==============================] - 1s 109us/step - loss: 2.1669 - acc: 0.4909 - val_loss: 2.0814 - val_acc: 0.5083\n",
            "Epoch 9/40\n",
            "8083/8083 [==============================] - 1s 110us/step - loss: 2.1279 - acc: 0.4955 - val_loss: 2.0792 - val_acc: 0.5161\n",
            "Epoch 10/40\n",
            "8083/8083 [==============================] - 1s 110us/step - loss: 2.1281 - acc: 0.5013 - val_loss: 2.0674 - val_acc: 0.5083\n",
            "Epoch 11/40\n",
            "8083/8083 [==============================] - 1s 106us/step - loss: 2.1212 - acc: 0.5001 - val_loss: 2.0706 - val_acc: 0.5139\n",
            "Epoch 12/40\n",
            "8083/8083 [==============================] - 1s 101us/step - loss: 2.1100 - acc: 0.5061 - val_loss: 2.0708 - val_acc: 0.5117\n",
            "Epoch 13/40\n",
            "8083/8083 [==============================] - 1s 100us/step - loss: 2.0858 - acc: 0.5096 - val_loss: 2.0715 - val_acc: 0.5117\n",
            "Epoch 14/40\n",
            "8083/8083 [==============================] - 1s 103us/step - loss: 2.0974 - acc: 0.5062 - val_loss: 2.0662 - val_acc: 0.5117\n",
            "Epoch 15/40\n",
            "8083/8083 [==============================] - 1s 104us/step - loss: 2.0985 - acc: 0.5095 - val_loss: 2.0637 - val_acc: 0.5128\n",
            "Epoch 16/40\n",
            "8083/8083 [==============================] - 1s 103us/step - loss: 2.0861 - acc: 0.5100 - val_loss: 2.0750 - val_acc: 0.5117\n",
            "Epoch 17/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0760 - acc: 0.5124 - val_loss: 2.0810 - val_acc: 0.5128\n",
            "Epoch 18/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0701 - acc: 0.5165 - val_loss: 2.0636 - val_acc: 0.5128\n",
            "Epoch 19/40\n",
            "8083/8083 [==============================] - 1s 113us/step - loss: 2.0688 - acc: 0.5149 - val_loss: 2.0618 - val_acc: 0.5117\n",
            "Epoch 20/40\n",
            "8083/8083 [==============================] - 1s 105us/step - loss: 2.0590 - acc: 0.5171 - val_loss: 2.0691 - val_acc: 0.5128\n",
            "Epoch 21/40\n",
            "8083/8083 [==============================] - 1s 101us/step - loss: 2.0531 - acc: 0.5196 - val_loss: 2.0818 - val_acc: 0.5150\n",
            "Epoch 22/40\n",
            "8083/8083 [==============================] - 1s 101us/step - loss: 2.0686 - acc: 0.5187 - val_loss: 2.0838 - val_acc: 0.5195\n",
            "Epoch 23/40\n",
            "8083/8083 [==============================] - 1s 104us/step - loss: 2.0403 - acc: 0.5196 - val_loss: 2.0710 - val_acc: 0.5139\n",
            "Epoch 24/40\n",
            "8083/8083 [==============================] - 1s 103us/step - loss: 2.0407 - acc: 0.5200 - val_loss: 2.0675 - val_acc: 0.5106\n",
            "Epoch 25/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0380 - acc: 0.5197 - val_loss: 2.0674 - val_acc: 0.5172\n",
            "Epoch 26/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0316 - acc: 0.5212 - val_loss: 2.0680 - val_acc: 0.5150\n",
            "Epoch 27/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0408 - acc: 0.5208 - val_loss: 2.0692 - val_acc: 0.5117\n",
            "Epoch 28/40\n",
            "8083/8083 [==============================] - 1s 103us/step - loss: 2.0393 - acc: 0.5246 - val_loss: 2.0847 - val_acc: 0.5117\n",
            "Epoch 29/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0305 - acc: 0.5234 - val_loss: 2.0719 - val_acc: 0.5139\n",
            "Epoch 30/40\n",
            "8083/8083 [==============================] - 1s 106us/step - loss: 2.0260 - acc: 0.5239 - val_loss: 2.0760 - val_acc: 0.5117\n",
            "Epoch 31/40\n",
            "8083/8083 [==============================] - 1s 120us/step - loss: 2.0199 - acc: 0.5268 - val_loss: 2.0756 - val_acc: 0.5139\n",
            "Epoch 32/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0221 - acc: 0.5263 - val_loss: 2.0709 - val_acc: 0.5195\n",
            "Epoch 33/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0159 - acc: 0.5270 - val_loss: 2.0867 - val_acc: 0.5228\n",
            "Epoch 34/40\n",
            "8083/8083 [==============================] - 1s 102us/step - loss: 2.0260 - acc: 0.5253 - val_loss: 2.0752 - val_acc: 0.5184\n",
            "Epoch 35/40\n",
            "8083/8083 [==============================] - 1s 103us/step - loss: 2.0234 - acc: 0.5239 - val_loss: 2.0763 - val_acc: 0.5206\n",
            "Epoch 36/40\n",
            "8083/8083 [==============================] - 1s 100us/step - loss: 2.0055 - acc: 0.5289 - val_loss: 2.0748 - val_acc: 0.5128\n",
            "Epoch 37/40\n",
            "8083/8083 [==============================] - 1s 103us/step - loss: 2.0167 - acc: 0.5227 - val_loss: 2.0848 - val_acc: 0.5150\n",
            "Epoch 38/40\n",
            "8083/8083 [==============================] - 1s 111us/step - loss: 2.0093 - acc: 0.5231 - val_loss: 2.0726 - val_acc: 0.5206\n",
            "Epoch 39/40\n",
            "8083/8083 [==============================] - 1s 113us/step - loss: 2.0094 - acc: 0.5234 - val_loss: 2.0769 - val_acc: 0.5195\n",
            "Epoch 40/40\n",
            "8083/8083 [==============================] - 1s 111us/step - loss: 2.0109 - acc: 0.5260 - val_loss: 2.0714 - val_acc: 0.5195\n",
            "2246/2246 [==============================] - 0s 42us/step\n",
            "\n",
            "Building network 2...\n",
            "Train on 8083 samples, validate on 899 samples\n",
            "Epoch 1/40\n",
            "8083/8083 [==============================] - 1s 182us/step - loss: 2.9508 - acc: 0.2750 - val_loss: 2.1868 - val_acc: 0.3726\n",
            "Epoch 2/40\n",
            "8083/8083 [==============================] - 1s 129us/step - loss: 2.2218 - acc: 0.4225 - val_loss: 1.9482 - val_acc: 0.5139\n",
            "Epoch 3/40\n",
            "8083/8083 [==============================] - 1s 125us/step - loss: 2.0115 - acc: 0.4801 - val_loss: 1.9140 - val_acc: 0.5551\n",
            "Epoch 4/40\n",
            "8083/8083 [==============================] - 1s 129us/step - loss: 1.9205 - acc: 0.5093 - val_loss: 1.8566 - val_acc: 0.5695\n",
            "Epoch 5/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.8665 - acc: 0.5196 - val_loss: 1.8378 - val_acc: 0.5684\n",
            "Epoch 6/40\n",
            "8083/8083 [==============================] - 1s 146us/step - loss: 1.8205 - acc: 0.5409 - val_loss: 1.8246 - val_acc: 0.5773\n",
            "Epoch 7/40\n",
            "8083/8083 [==============================] - 1s 141us/step - loss: 1.8074 - acc: 0.5383 - val_loss: 1.8127 - val_acc: 0.5717\n",
            "Epoch 8/40\n",
            "8083/8083 [==============================] - 1s 134us/step - loss: 1.7697 - acc: 0.5494 - val_loss: 1.8148 - val_acc: 0.5717\n",
            "Epoch 9/40\n",
            "8083/8083 [==============================] - 1s 137us/step - loss: 1.7487 - acc: 0.5554 - val_loss: 1.8175 - val_acc: 0.5873\n",
            "Epoch 10/40\n",
            "8083/8083 [==============================] - 1s 143us/step - loss: 1.7301 - acc: 0.5581 - val_loss: 1.7997 - val_acc: 0.5929\n",
            "Epoch 11/40\n",
            "8083/8083 [==============================] - 1s 142us/step - loss: 1.7128 - acc: 0.5641 - val_loss: 1.8061 - val_acc: 0.5706\n",
            "Epoch 12/40\n",
            "8083/8083 [==============================] - 1s 141us/step - loss: 1.6903 - acc: 0.5692 - val_loss: 1.7840 - val_acc: 0.5873\n",
            "Epoch 13/40\n",
            "8083/8083 [==============================] - 1s 140us/step - loss: 1.6799 - acc: 0.5716 - val_loss: 1.8099 - val_acc: 0.5873\n",
            "Epoch 14/40\n",
            "8083/8083 [==============================] - 1s 135us/step - loss: 1.6668 - acc: 0.5754 - val_loss: 1.7708 - val_acc: 0.5818\n",
            "Epoch 15/40\n",
            "8083/8083 [==============================] - 1s 128us/step - loss: 1.6644 - acc: 0.5760 - val_loss: 1.7856 - val_acc: 0.5918\n",
            "Epoch 16/40\n",
            "8083/8083 [==============================] - 1s 129us/step - loss: 1.6382 - acc: 0.5810 - val_loss: 1.7636 - val_acc: 0.5962\n",
            "Epoch 17/40\n",
            "8083/8083 [==============================] - 1s 129us/step - loss: 1.6334 - acc: 0.5811 - val_loss: 1.7734 - val_acc: 0.5951\n",
            "Epoch 18/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.6159 - acc: 0.5914 - val_loss: 1.7587 - val_acc: 0.6107\n",
            "Epoch 19/40\n",
            "8083/8083 [==============================] - 1s 131us/step - loss: 1.6111 - acc: 0.5862 - val_loss: 1.7549 - val_acc: 0.6007\n",
            "Epoch 20/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.5985 - acc: 0.5958 - val_loss: 1.7541 - val_acc: 0.5984\n",
            "Epoch 21/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.5814 - acc: 0.5990 - val_loss: 1.7110 - val_acc: 0.6040\n",
            "Epoch 22/40\n",
            "8083/8083 [==============================] - 1s 132us/step - loss: 1.5721 - acc: 0.5990 - val_loss: 1.7438 - val_acc: 0.5840\n",
            "Epoch 23/40\n",
            "8083/8083 [==============================] - 1s 127us/step - loss: 1.5694 - acc: 0.5990 - val_loss: 1.7534 - val_acc: 0.6007\n",
            "Epoch 24/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.5595 - acc: 0.5977 - val_loss: 1.7279 - val_acc: 0.6073\n",
            "Epoch 25/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.5577 - acc: 0.6034 - val_loss: 1.7266 - val_acc: 0.6062\n",
            "Epoch 26/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.5449 - acc: 0.6041 - val_loss: 1.7395 - val_acc: 0.6040\n",
            "Epoch 27/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.5270 - acc: 0.6071 - val_loss: 1.7525 - val_acc: 0.6018\n",
            "Epoch 28/40\n",
            "8083/8083 [==============================] - 1s 123us/step - loss: 1.5127 - acc: 0.6118 - val_loss: 1.6821 - val_acc: 0.6129\n",
            "Epoch 29/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.5147 - acc: 0.6150 - val_loss: 1.7299 - val_acc: 0.6140\n",
            "Epoch 30/40\n",
            "8083/8083 [==============================] - 1s 134us/step - loss: 1.5004 - acc: 0.6161 - val_loss: 1.7238 - val_acc: 0.5940\n",
            "Epoch 31/40\n",
            "8083/8083 [==============================] - 1s 135us/step - loss: 1.4926 - acc: 0.6194 - val_loss: 1.6708 - val_acc: 0.6240\n",
            "Epoch 32/40\n",
            "8083/8083 [==============================] - 1s 132us/step - loss: 1.4800 - acc: 0.6220 - val_loss: 1.7485 - val_acc: 0.6151\n",
            "Epoch 33/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.4711 - acc: 0.6251 - val_loss: 1.6899 - val_acc: 0.6218\n",
            "Epoch 34/40\n",
            "8083/8083 [==============================] - 1s 132us/step - loss: 1.4686 - acc: 0.6224 - val_loss: 1.7119 - val_acc: 0.6174\n",
            "Epoch 35/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.4572 - acc: 0.6337 - val_loss: 1.7115 - val_acc: 0.6274\n",
            "Epoch 36/40\n",
            "8083/8083 [==============================] - 1s 129us/step - loss: 1.4389 - acc: 0.6350 - val_loss: 1.7191 - val_acc: 0.6318\n",
            "Epoch 37/40\n",
            "8083/8083 [==============================] - 1s 129us/step - loss: 1.4327 - acc: 0.6363 - val_loss: 1.7018 - val_acc: 0.6263\n",
            "Epoch 38/40\n",
            "8083/8083 [==============================] - 1s 130us/step - loss: 1.4300 - acc: 0.6354 - val_loss: 1.7529 - val_acc: 0.6352\n",
            "Epoch 39/40\n",
            "8083/8083 [==============================] - 1s 128us/step - loss: 1.4207 - acc: 0.6369 - val_loss: 1.6779 - val_acc: 0.6407\n",
            "Epoch 40/40\n",
            "8083/8083 [==============================] - 1s 132us/step - loss: 1.4095 - acc: 0.6407 - val_loss: 1.6812 - val_acc: 0.6485\n",
            "2246/2246 [==============================] - 0s 55us/step\n",
            "\n",
            "Network 1 results\n",
            "Hyperparameters: {'n_dense': 6, 'dense_units': 16, 'activation': 'relu', 'dropout': <class 'keras.layers.core.Dropout'>, 'dropout_rate': 0.5, 'kernel_initializer': 'glorot_uniform', 'optimizer': 'sgd'}\n",
            "Test score: 2.0857295803161784\n",
            "Test accuracy: 0.5267141585305453\n",
            "Network 2 results\n",
            "Hyperparameters: {'n_dense': 6, 'dense_units': 16, 'activation': 'selu', 'dropout': <class 'keras.layers.noise.AlphaDropout'>, 'dropout_rate': 0.1, 'kernel_initializer': 'lecun_normal', 'optimizer': 'sgd'}\n",
            "Test score: 1.635102783476574\n",
            "Test accuracy: 0.6393588602489801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUcIQEZFclDBERCQXJQwREcnl/zJ7cxx1R4X2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGhV4ustfv95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}